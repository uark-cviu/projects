
<p align="center">
  <a href="https://arxiv.org/abs/2406.01029">
    <h1>HyperGLM: HyperGraph for Video Scene Graph Generation and Anticipation (CVPR 2025)</h1>
  </a>
</p>

<!-- [Trong-Thuan Nguyen](https://scholar.google.com/citations?user=ty0Njf0AAAAJ&hl=vi&authuser=1), [Pha Nguyen](https://pha-nguyen.github.io/), [Xin Li](https://scholar.google.com/citations?user=gMBvzGoAAAAJ&hl=vi), [Jackson Cothren](https://scholar.google.com/citations?user=_WB9fo4AAAAJ&hl=vi&oi=ao), [Alper Yilmaz](https://scholar.google.com/citations?user=MeQC1XYAAAAJ&hl=vi&oi=ao), [Khoa Luu](https://scholar.google.com/citations?user=JPAl8-gAAAAJ) -->
<p align="center">
  <a href="https://scholar.google.com/citations?user=ty0Njf0AAAAJ&hl=vi&authuser=1/" target="_blank">Trong-Thuan Nguyen</a>, 
  <a href="https://pha-nguyen.github.io/" target="_blank">Pha Nguyen</a>, 
  <a href="https://scholar.google.com/citations?user=_WB9fo4AAAAJ&hl=vi&oi=ao" target="_blank">Jackson Cothren</a>, 
  <a href="https://scholar.google.com/citations?user=MeQC1XYAAAAJ&hl=vi&oi=ao" target="_blank">Alper Yilmaz</a>, 
  <a href="https://scholar.google.com/citations?user=JPAl8-gAAAAJ" target="_blank">Khoa Luu</a>
</p>

Abstract
--------

Multimodal LLMs have advanced vision-language tasks but still struggle with understanding video scenes. To bridge this gap, Video Scene Graph Generation (VidSGG) has emerged to capture multi-object relationships across video frames. However, prior methods rely on pairwise connections, limiting their ability to handle complex multi-object interactions and reasoning. To this end, we propose Multimodal LLMs on a Scene HyperGraph (HyperGLM), promoting reasoning about multi-way interactions and higher-order relationships. Our approach uniquely integrates entity scene graphs, which capture spatial relationships between objects, with a procedural graph that models their causal transitions, forming a unified HyperGraph. Significantly, HyperGLM enables reasoning by injecting this unified HyperGraph into LLMs. Additionally, we introduce a new Video Scene Graph Reasoning (VSGR) dataset featuring 1.9M frames from third-person, egocentric, and drone views and supports five tasks: Scene Graph Generation, Scene Graph Anticipation, Video Question Answering, Video Captioning, and Relation Reasoning. Empirically, HyperGLM consistently outperforms state-of-the-art methods across five tasks, effectively modeling and reasoning complex relationships in diverse video scenes.

Key Contributions
------------
- Proposes a unified Scene HyperGraph that integrates spatial relationships (entity scene graphs) and causal transitions (procedural graphs), enabling higher-order reasoning beyond pairwise connections in Multimodal LLMs for improved Video Scene Graph Generation (VidSGG).</li>

- Introduces the Video Scene Graph Reasoning (VSGR) dataset with 1.9M frames from third-person, egocentric, and drone views, supporting five key tasks (Scene Graph Generation, Scene Graph Anticipation, Video Question Answering, Video Captioning, and Relation Reasoning).</li>



This page was built using the [Academic Project Page Template](https://github.com/eliahuhorwitz/Academic-project-page-template).  
This website is licensed under a [Creative Commons Attribution-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-sa/4.0/).